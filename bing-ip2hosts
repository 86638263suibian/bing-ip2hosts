#!/bin/bash
#
# bing-ip2hosts - Enumerate hostnames from Bing.com for an IP address.
# Bing.com is Microsoft's search engine which has an IP: search parameter.
#
# Copyright (C) 2019 Andrew Horton aka urbanadventurer
# Homepage: http://www.morningstarsecurity.com/research/bing-ip2hosts
#
# License: GPLv3
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, version 3 of the License.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.


VERSION=0.6
TMP_DIR=/tmp
QUIET=0
OUTPUT_IP=0
DISPLAY_URL_PREFIX=1
IP=
PREFIX=
SUFFIX=
DEBUG=0
STOP_AFTER_PAGES=5
BING_SETLANG=en-us
BING_SETMKT=

N="\e[0;0m"  #NORMALe
W="\e[0;97m" #WHITE
R="\e[0;31m" #RED
DR="\e[1;31m" #RED
G="\e[0;32m" #GREEN
Y="\e[1;33m" #YELLOW
B="\e[0;34m" #BLUE
DG="\e[1;30m" #DARKGRAY

trap ctrl_c INT

function ctrl_c() {
  echo -e "\n* ^C"

  # clean up tmp files
  if [[ $DEBUG == 0 ]]; then
    rm -f "$f_scraped_html"
  fi

  show_hosts
  exit 1
}

function banner() {
BANNER="
$G  m,                $N   .,recon:,        ,,
$G  #####             $N  ]##\"\"^^\"%##m    %##b
$G  ####b             $N  ]##      \`##b
$G  ####b             $N  ]##       ##    i##    @#b,######m       ,######m ##b
$G  ####b 1mw,        $N  ]##MMM####      i##    ]###\`    %##     ###\`    \`@##
$G  ####b  1#####Nw,  $N  ]##\`\`    @#b    i##    ]##       ###   ###       j##
$G  ####i   %########[$N  ]##       @##   i##    ]##       ###   ##g       j##
$G  ####n      2#####[$N  ]##      @##    i##    ]##       ###   @##       {##
$G  ####g  ,#########b$N  ]##   ,,e###    j##    ]##       ###    7##m,,,s#M##
$G  #############M^   $N  'WWWWWW%b^       ii    'nn       nn*      \`1337\` g##
$G  ##########\"      $N                                                    G##
$G    \"%##\"         $N                                            @#Gmmem###G
  ,i             $G   ,s2e,    $N ##                                  \`\`\`\`
   \`            $G   \"\`   %#$N    ##                             T#
  ]#   ]#,#M5@#p $G        #b  $N #H#H%@#     s#M5O#o   ,#MSSM  W@##W=  s#SSW
  ]#   j#p    ^#p$G      ,#M   $N ##    @#   ##'   'O#  S#,      ]#     #b
  ]#   j#      #M$G    ,#M     $N ##    @#   #o     O#    \"SXm   ]#      ^\"@#
  ]#   j##,  ,## $G  ,#2       $N ##    @#   7#.   .#O  ,   ]#   ]#Q       ,#s
  ]#   j######'  $G  #######x  $N ##    @#    s#####o    ####^    #Tt    ####^
       j#
$N       j#         $W bing-ip2hosts ($VERSION) by Andrew Horton @urbanadventurer
$N       j#         $W https://morningstarsecurity.com/research/bing-ip2hosts
$N                  $W https://github.com/urbanadventurer/bing-ip2hosts$N
"

echo -e "$BANNER"
}


function display_progress() {

PROGRESS="$G  m,           $DG -----.--[$N bing-ip2hosts v$VERSION $DG]-------------------------
$G  #####             $DG | $N Searching    : $IP
$G  ####b             $DG | $N$Y Total Found  : $uniq_hosts 
$G  ####b             $DG | $N Scraped pages: $page  
$G  ####b 1mw,        $DG | $N 
$G  ####b  1#####Nw,  $DG | $N Page Title   : $page_title
$G  ####i   %########[$DG | $N Results      : $results_count
$G  ####n      2#####[$DG | $N Paginated    : $results_highlighted_page
$G  ####g  ,#########b$DG | $N New          : $new_results new
$G  #############M^   $DG | $N   
$G  ##########\"       $DG | $N   
$G    \"%##\"           $DG | $N CTRL-C to stop

${N}[ ] /$urlpath"

#progress_animation="⣾⣽⣻⢿⡿⣟⣯⣷"
progress_animation="▏▎▍▌▋▊▉▊▋▌▍▎"

clear
echo -e "$PROGRESS"
echo -e "${B}$vhosts${N}"

x=$(($page % 8))
tput cup 13 1
echo -e "$DR${progress_animation:$x:1}"
tput cup 24 0

}

function show_hosts() {
  if [[ $QUIET == 0 ]]; then
    #clear
    echo -e "$N"
  fi

  uniq_hosts=`cat "$f_results" | sort | uniq`
  count_uniq_hosts=`cat "$f_results" | sort | uniq | wc -l`
  echo "Found $count_uniq_hosts after scraping $page pages."
  echo

  if [[ $DEBUG == 0 ]]; then
    rm -f "$f_results"
  fi

  if [[ $OUTPUT_IP == 1 ]]; then
    PREFIX="$IP,"
  fi

  if [[ $DISPLAY_URL_PREFIX == 1 ]]; then
    SUFFIX="/"
  fi

  for h in `echo "$uniq_hosts"`
  do
    echo "$PREFIX$h$SUFFIX"
  done

  if [[ ! -z "$OUTPUT_FILE" ]]; then
    for h in `echo "$uniq_hosts"`
    do
      echo "$PREFIX$h$SUFFIX" >> "$OUTPUT_FILE"
    done
  fi
  echo
}


if [[ -z "$1" ]] || [[ "$1" == "-h" ]] || [[ "$1" == "--help" ]]; then
clear
banner

echo -e "bing-ip2hosts is a Bing.com web scraper that discovers websites by IP address.
Use for OSINT and discovering attack-surface of penetration test targets.

Find hostnames that share an IP address with your target which can be a hostname or an IP address.
This uses the Bing.com feature of seaching by IP address, e.g. \"IP:40.112.72.205\".

Usage: $0 [OPTIONS] IP|hostname

OPTIONS are:
-o FILE\tOutput hostnames to FILE.
-n NUM\tStop after NUM scraped pages return no new results (Default: $STOP_AFTER_PAGES).
-l\tSelect the language for use in the setlang parameter (Default: $BING_SETLANG).
-m\tSelect the market for use in the setmkt parameter (Default is unset).
-u\tOnly display hostnames. Default is to include URL prefixes.
-i\tCSV output. Outputs the IP and hostname on each line, separated by a comma.
-q\tQuiet. Disable output except for final results.
-t DIR\tUse this directory instead of /tmp.
"
exit 1
fi

while getopts "o:n:l:m:uiqt:" optionName; do
  case "$optionName" in
    o) OUTPUT_FILE=$OPTARG;;
    n) STOP_AFTER_PAGES=$OPTARG;;
    l) BING_SETLANG="$OPTARG";;
    m) BING_SETMKT="$OPTARG";;
    u) DISPLAY_URL_PREFIX=0;;
    i) OUTPUT_IP=1;;
    q) QUIET=1;;
    t) TMP_DIR="$OPTARG";;
[?]) echo "Error"; exit 1;;
esac
done

shift $(($OPTIND -1))

if [[ -z "$1" ]]; then
  echo "Missing IP address or hostname." >&2
  exit 1
fi

# initialize outputfile
if [[ ! -z "$OUTPUT_FILE" ]]; then
  touch "$OUTPUT_FILE"
  if [[ ! -w "$OUTPUT_FILE" ]]; then
    echo "Cannot write to $OUTPUT_FILE." >&2
    exit 1
  fi
fi

# Create TMP_DIR if necessary
if [[ ! -d "$TMP_DIR" ]]; then
  if [[ "$QUIET" == 0 ]]; then
    mkdir -v -p "$TMP_DIR"
  else
    mkdir -p "$TMP_DIR"
  fi
  if [[ ! "$?" == 0 ]]; then
    echo "Invalid TMP Directory: $TMP_DIR." >&2
    exit 1
  fi
fi

if [[ $QUIET == 0 ]]; then
  clear
fi

animation="/-\|"
page=0
last_page_check=
results_count=1
uniq_hosts=0
single_page=
results_removed=
declare -a scrape_results

stop_sequence="0"
for ((i = 0; i < (($STOP_AFTER_PAGES-1)); i++)); do stop_sequence+=" 0"; done

# if the parameter looks like an IP go ahead, otherwise resolve it
if [[ "$1" =~ ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
  IP="$1"
else
  # IP=`resolveip -s "$1"`
  IP=`nslookup "$1" | egrep "^Address: \w+\.\w+\.\w+\.\w+$" | tail -1 | awk '{ print $2 }'`
  #  dig -t a treshna.com  +short
  if [ "$IP" == "" ]; then
    echo "Cannot resolve $1 to an IP address." >&2
    exit 1
  fi
fi

f_results=`mktemp -p $TMP_DIR -t bing-ip2hosts.tmp.XXXXXX`

while true; do

  url="https://www.bing.com/search?q=ip%3A$IP+.&qs=n&first=${page}0&FORM=PERE&setlang=$BING_SETLANG&setmkt=$BING_SETMKT"
  urlpath=`echo "$url" | cut -d '/' -f 4-`

  f_scraped_html=`mktemp -p "$TMP_DIR" -t bing-ip2hosts.tmp.XXXXXX`
  if ! wget --quiet --no-check-certificate --output-document "$f_scraped_html" "$url"; then
    echo -e "\n${R}wget failed to scrape $url" >&2
    exit 1
  fi

  last_page_check=`egrep -o '<span class="sb_count">[0-9]+-([0-9]+) of (\1) results' $f_scraped_html`
  results_count=`egrep -o '<span class="sb_count">[^<]+' $f_scraped_html|cut -d '>' -f 2|cut -d ' ' -f 1-3`
  single_page=`egrep -o '<span class="sb_count">[0-9] results' $f_scraped_html`
  results_removed=`egrep -o '>Some results have been removed<' $f_scraped_html`
  page_title=`egrep -o '<title>([^<]+)' $f_scraped_html | cut -d '>' -f 2`
  results_highlighted_page=`egrep -o "class=\"sb_pagS sb_pagS_bp b_widePag sb_bp\">([0-9]+)" $f_scraped_html | cut -d '>' -f 2`

  # no captcha support or detection
  # pages will contain "Typing the characters in the picture above helps us ensure that a person, not a program, is performing a search"

  results=`cat "$f_scraped_html"| egrep -o "<h2><a href=\"[^\"]+" $f_scraped_html | cut -d '"' -f 2`

  if [[ $DISPLAY_URL_PREFIX == 1 ]]; then
    vhosts=`echo "$results" | cut -d '/' -f 1-3 | tr '[:upper:]' '[:lower:]'`
  else
    vhosts=`echo "$results" | cut -d '/' -f 3 | tr '[:upper:]' '[:lower:]'`
  fi
  echo -e "$vhosts" >> "$f_results"

  old_uniq_hosts=$uniq_hosts
  uniq_hosts=`cat "$f_results" | sort | uniq | wc -l`

  if [[ "$DEBUG" == 1 ]]; then
    echo
    echo "[debug] Page: $page"
    echo
    echo "Results page checks:"
    echo "[debug] Results Count: $results_count"
    echo "[debug] Last Page: $last_page_check"
    echo "[debug] Single Page: $single_page"
    echo "[debug] Results Removed: $results_removed"

    echo "Counting results:"
    echo "[debug] uniq_hosts = $uniq_hosts"
    echo "[debug] old_uniq_hosts = $old_uniq_hosts"
    echo "[debug] Found $new_results new results"
    echo "[debug] scrape_results array ${scrape_results[@]}"
  fi

  # how many new results did we get
  new_results=$(( uniq_hosts - old_uniq_hosts ))
  scrape_results+=($new_results)


  if [[ $QUIET == 0 ]]; then
  #  echo -ne "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
  #  echo -en "[${animation: $(( $page % 4 )) :1}][ $IP | Scraping page $((page + 1)) | Results: $results_count | Found $uniq_hosts ]          "
    display_progress
  fi

  # clean up tmp files
  if [[ $DEBUG == 0 ]]; then
    rm -f "$f_scraped_html"
  fi

  # check end conditions
  if [[ ! -z "$last_page_check" ]]; then
    if [[ $QUIET == 0 ]]; then
      echo -e "\n${R}Stopping. This is the last page of results." >&2
    fi
    break
  fi

  if [[ ! -n "$results_count" ]]; then
    if [[ $QUIET == 0 ]]; then
      echo -e "\n${R}Stopping. The search results count is missing." >&2
    fi
    break
  fi

  if [[ ! -z "$single_page" ]]; then
    if [[ $QUIET == 0 ]]; then
      echo -e "\n${R}Stopping. Returned only one page of results." >&2
    fi
    break
  fi

  if [[ ${scrape_results[@]} =~ $stop_sequence ]]; then
    if [[ $QUIET == 0 ]]; then
      echo -e "\n${R}Stopping after scraping $STOP_AFTER_PAGES pages without any new results.$N" >&2
    fi

    break
  fi

  let page=$page+1
done

show_hosts
